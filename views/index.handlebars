<h1>Welcome to Image-to-Sound!</h1>
<p>
    Modern research on neuroplasticity has indicated that in blind individuals, 
    the brain can reroute non-visual sense information to the visual cortex,
    effectively enabling people to see by other means 
    (<a target="_blank" href="https://www.ncbi.nlm.nih.gov/pubmed/8606771">Here's a link to one 
    such study</a>). This app draws inspiration from some of that research.
<p>
    I'm interested in whether the brain can learn to "see" by listening to sounds 
    which have been generated by an image. This is an app takes an image and maps 
    it to sound in a way that should convey spatial information.
</p>
<p>
    In the process of building the app, I also came across a real-world device
    (called the vOIce) which does pretty much the same thing, and 
    <a target="_blank" href="https://www.wired.com/2017/03/book-excerpt-body-builders/">
    there have already been some success stories</a> where blind people were able to 
    distinguish objects and navigate their environment using the device. 
    <a target="_blank" href="https://www.seeingwithsound.com/">You can find out more 
    info about the vOIce here.</a> I'm not associated with that project, but I think 
    it's pretty fascinating and you should check it out.
</p>
<p>
    This app is more of a proof of concept that you can play around with in the
    browser to test how "seeing with sound" might work.
</p>

<h2>How it works</h2>
<p>Image are divided into pixels, and we can associate each pixel with some sound
    information. The height of a pixel in the images corresponds to its pitch.
    Pixels higher up will have a higher pitch, and pixels lower in the image
    have lower pitch. The brightness (or lumocity) of each pixel corresponds
    to how loud it sounds when the image is played.
</p>
<p>Once each pixel has been associated with a pitch and a volume, the image is
    scanned column by column from left to right. You'll hear objects on the
    left side of the image first, and images on the right side after. The sound
    also pans from left to right as the image is scanned, to help convey spatial
    relationships.
</p>

<h2>Try it out!</h2>
<p>You can try a demo with some pre-given images:</p>
<p><a href="/demo"><button>Try the demo</button></a></p>
<p>Or you can upload your own images and hear what they sound like:</p>
<p><a href="/upload"><button>Upload your own image</button></a></p>
<p>NOTE: This app uses the Web Audio API, which is only supported in modern
    browsers, and is not supported in Internet Explorer at all. 
    <a target="_blank" href="https://caniuse.com/#feat=audio-api">
        See if your browser is compatable here.
    </a>
</p>

<h2>Limitations</h2>
<p>Right now, the app can only process images up to 128 x 64 in resolution.
    In principle, the image processing algorithm could process larger images, but 
    the bottleneck is actually the Web Audio API, which I have limited control over.
    At higher resolutions, the Web Audio API starts to run into performance problems
    when it tries to play back the sound.
</p>
<p>Additionally, there are physical limits to how well humans can distinguish between
    pitches that are close together. At much higher resolutions, the user wouldn't
    be able to glean much more information from the sound anyway.
</p>
